# app.py

import streamlit as st
from rag_pipeline.loader import load_documents, extract_images_from_pdf
from rag_pipeline.chunker import chunk_by_method
from rag_pipeline.embedder import (
    CLIPImageEmbedder, CLIPTextEmbedder,
    get_text_embedder, get_image_embedder,
    get_hybrid_embedder
)
from rag_pipeline.es_uploader import (
    upload_image_embeddings_to_es, search_similar_images,
    upload_text_chunks_to_es
)
from rag_pipeline.retriever import search_similar_text
from rag_pipeline.reranker import rerank_cosine, rerank_crossencoder
from langchain.embeddings import HuggingFaceEmbeddings
from rag_pipeline.llm_engine import run_llm_qa

from langchain.llms import OpenAI  # ë˜ëŠ” KoAlpaca ë“±
import numpy as np


st.set_page_config(page_title="ğŸ“š RAG ì‹¤í—˜ì‹¤", layout="wide")
st.title("ğŸ“„ PDF ê¸°ë°˜ RAG ì‹¤í—˜")

mode = st.sidebar.selectbox("ëª¨ë“œ ì„ íƒ", ["text", "image_ocr", "image_embed"])
embedding_model = st.sidebar.selectbox("embedding ëª¨ë¸", {
    "text" : ["sbert", "openai", "jina"],
    "image_ocr" : ["sbert", "openai"],
    "image_embed" : ["clip", "siglip"]
}[mode])
chunking_method = None
if mode in ["text", "image_ocr"]:
    chunking_method = st.sidebar.selectbox("chunking ë°©ë²•", ["recursive", "token","sentence"])
elif mode == "image_embed":
    st.sidebar.markdown("ì²­í‚¹ ë°©ë²• : ì—†ìŒ (ì´ë¯¸ì§€ ì„ë² ë”© ëª¨ë“œ)")
retriever_method = st.sidebar.selectbox("retriever ë°©ë²•", ["elasticsearch", "hybrid_es","hybrid_embedding","faiss"])
if mode == "image_embed":
    st.sidebar.markdown("rerank ë°©ë²• : ì—†ìŒ (ì´ë¯¸ì§€ ì„ë² ë”© ëª¨ë“œ)")
    rerank_method = "none"
else:
    rerank_method = st.sidebar.selectbox("rerank ë°©ë²•", ["none", "cosine", "crossencoder"])
# rerank_method = st.sidebar.selectbox("rerank ë°©ë²•", ["none", "cosine", "crossencoder"])


with st.sidebar.expander("ğŸ§ª í˜„ì¬ ì‹¤í—˜ ì¡°í•© ë³´ê¸°", expanded=True):
    st.markdown("**âœ… ì„ íƒëœ ì‹¤í—˜ ì„¤ì •**")
    st.write(f"ğŸ”¹ ëª¨ë“œ : `{mode}`")
    st.write(f"ğŸ”¹ ì„ë² ë”© ëª¨ë¸: `{embedding_model}`")
    if chunking_method:
        st.write(f"ğŸ”¹ ì²­í‚¹ ë°©ë²•: `{chunking_method}`")
    else:
        st.write("ğŸ”¹ ì²­í‚¹ ë°©ë²•: ì—†ìŒ (image embedding mode)")
    st.write(f"ğŸ”¹ ê²€ìƒ‰ ë°©ë²• : `{retriever_method}`")
    st.write(f"ğŸ”¹ ë¦¬ë­í‚¹ ë°©ë²•: `{rerank_method}`")


def get_embedder(mode, model_name):
    if mode in ["text", "image_ocr"]:
        return get_text_embedder(model_name)
    elif mode == "image_embed":
        return get_image_embedder(model_name)
    elif mode == "text" and retriever_method == "hybrid_embedding":
        return get_hybrid_embedder()

if st.sidebar.button("ğŸ“‚ ë¬¸ì„œ ì¸ë±ì‹± ì‹¤í–‰"):
    # embeddr = HuggingFaceEmbeddings(model_name="snunlp/KR-SBERT-V40K-klueNLI-augSTS")
    # embeddr = get_embedder(mode, embedding_model)
    if retriever_method == "hybrid_embedding":
        text_embedder, image_embedder = get_hybrid_embedder()
    else:
        embeddr = get_embedder(mode, embedding_model)

    if mode in ["text", "image_ocr"]:
        st.info("ğŸ” ë¬¸ì„œ ë¡œë”© ì¤‘...")
        raw_docs = load_documents(mode="text" if mode == "text" else "image")

        st.write("### ğŸ“„ ë¬¸ì„œë³„ í…ìŠ¤íŠ¸ ê¸¸ì´")
        for i, doc in enumerate(raw_docs):
            st.markdown(f"**ë¬¸ì„œ {i+1}: {doc['meta'].get('source', 'unknown')}**")
            st.write(f"ë¬¸ì ìˆ˜: {len(doc['content'])}")
            st.code(doc['content'][:300])

        st.info(f"âœ‚ï¸ ì²­í‚¹ ì‹œì‘... ({chunking_method} ë°©ì‹)")
        chunks = chunk_by_method(raw_docs, method=chunking_method)

        st.success(f"âœ… ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
        st.write("### âœ‚ï¸ ì¼ë¶€ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°")
        for i, doc in enumerate(chunks[:3]):
            st.markdown(f"**Chunk {i+1}:**")
            st.code(doc.page_content[:500])

        st.info("ğŸ§  ì„ë² ë”© ìˆ˜í–‰ ì¤‘...")
        texts = [doc.page_content for doc in chunks]
        # vectors = embeddr.embed_documents(texts)
        if retriever_method == "hybrid_embedding":
            vectors = [text_embedder.embed_query(t) for t in texts]
        else:
            vectors = embeddr.embed_documents(texts)

        st.success(f"âœ… ì„ë² ë”© ì™„ë£Œ (vector shape: {len(vectors)} x {len(vectors[0])})")
        st.write("### ğŸ”¢ ì²«ë²ˆì§¸ ì„ë² ë”© ë²¡í„° ë¯¸ë¦¬ë³´ê¸°")
        st.code(str(vectors[0][:10]) + " ...")

        # ì—…ë¡œë“œ
        # metadatas = [doc.metadata for doc in chunks]
        # if mode == "text":
        #     if retriever_method == "hybrid_es":
        #         index_name = "text_docs_hybrid"
        #     else:
        #         index_name = "text_docs"
        # elif mode == "image_ocr":
        #     index_name = "ocr_docs"
        # else:
        #     index_name = "image_embed_docs"

        index_name = "text_docs"
        if retriever_method == "hybrid_es":
            index_name = "text_docs_hybrid"
        elif mode == "image_ocr":
            index_name = "ocr_docs"

        # upload_text_chunks_to_es(chunks, embeddr, index_name=index_name)
        upload_text_chunks_to_es(chunks, text_embedder if retriever_method == "hybrid_embedding" else embeddr, index_name=index_name)
        st.success("âœ… Elasticsearch ì—…ë¡œë“œ ì™„ë£Œ!")

        if retriever_method == "hybrid_embedding":
            from os import listdir
            from os.path import join
            all_images = []
            for fname in listdir("docs"):
                if fname.endswith(".pdf"):
                    images = extract_images_from_pdf(join("docs", fname))
                    all_images.extend(images)
            image_vectors = [image_embedder.embed_image(img) for img, _ in all_images]
            image_metas = [meta for _, meta in all_images]
            upload_image_embeddings_to_es(image_vectors, image_metas)
            st.success("âœ… hybrid ì´ë¯¸ì§€ ë²¡í„° ì—…ë¡œë“œ ì™„ë£Œ!")

    # if mode == "text":
    #     raw_docs = load_documents(mode="text")
    #     chunks = chunk_by_method(raw_docs, method=chunking_method)
    #     upload_text_chunks_to_es(chunks, embeddr, index_name="text_docs")
    #     # embedder = HuggingFaceEmbeddings(model_name="snunlp/KR-SBERT-V40K-klueNLI-augSTS")
    #     # TODO: embed + upload to FAISS or Elasticsearch
    #     st.success("âœ… í…ìŠ¤íŠ¸ ì„ë² ë”© ë° ì—…ë¡œë“œ ì™„ë£Œ!")

    # elif mode == "image_ocr":
    #     raw_docs = load_documents(mode="image")
    #     chunks = chunk_by_method(raw_docs, method=chunking_method)
    #     upload_text_chunks_to_es(chunks, embeddr, index_name="ocr_docs")
    #     # embedder = HuggingFaceEmbeddings(model_name="snunlp/KR-SBERT-V40K-klueNLI-augSTS")
    #     # TODO: embed + upload to FAISS or Elasticsearch
    #     st.success("âœ… ì´ë¯¸ì§€ OCR ì„ë² ë”© ë° ì—…ë¡œë“œ ì™„ë£Œ!")

    elif mode == "image_embed":
        image_embedder = get_image_embedder(embedding_model)
        # all_images = []
        
        from os import listdir
        from os.path import join

        # st.info("ğŸ” PDFì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘...")

        # for fname in listdir("docs"):
        #     if fname.endswith(".pdf"):
        #         images = extract_images_from_pdf(join("docs", fname))
        #         all_images.extend(images)

        # st.success(f"âœ… ì´ {len(all_images)}ê°œ ì´ë¯¸ì§€ ì¶”ì¶œë¨")

        if "all_images" not in st.session_state:
            st.info("ğŸ“„ PDFì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘...")
            all_images = []
            for fname in listdir("docs"):
                if fname.endswith(".pdf"):
                    images = extract_images_from_pdf(join("docs", fname))
                    all_images.extend(images)
            st.session_state.all_images = all_images
            st.success(f"âœ… ì´ {len(all_images)}ê°œ ì´ë¯¸ì§€ ì¶”ì¶œë¨")
        else:
            all_images = st.session_state.all_images
            st.success(f"âœ… ì´ë¯¸ì§€ ìºì‹œ ë¡œë“œ ì™„ë£Œ (ì´ {len(all_images)}ê°œ)")

        # ì´ë¯¸ì§€ ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸° (Streamlitì—ì„œ PIL ì´ë¯¸ì§€ ë³´ì—¬ì£¼ê¸°)
        st.markdown("### ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ 3ì¥)")
        for i, (img, meta) in enumerate(all_images[:3]):
            st.image(img, caption=f"{meta.get('source')} - p{meta.get('page')}", use_column_width=True)

        if "image_vectors" not in st.session_state:
            st.info("ğŸ§  ì´ë¯¸ì§€ ì„ë² ë”© ì¤‘...")
            vectors = [image_embedder.embed_image(img) for img, _ in all_images]
            metadatas = [meta for _, meta in all_images]
            st.session_state.image_vectors = vectors
            st.session_state.image_metadatas = metadatas
            st.success(f"âœ… ì„ë² ë”© ì™„ë£Œ (vector dim: {len(vectors[0])})")
            st.code(f"ì²« ë²ˆì§¸ ë²¡í„° preview: {vectors[0][:10]} ...")
            st.write("### ğŸ“ ì˜ˆì‹œ ë©”íƒ€ë°ì´í„°:")
            st.json(metadatas[0])
            upload_image_embeddings_to_es(vectors, metadatas)
            st.success("âœ… ì´ë¯¸ì§€ ì„ë² ë”© ë° ì—…ë¡œë“œ ì™„ë£Œ!")
        else:
            vectors = st.session_state.image_vectors
            metadatas = st.session_state.image_metadatas
            st.success("âœ… (ìºì‹œ) ì„ë² ë”© ì™„ë£Œ ë° ì—…ë¡œë“œ ì™„ë£Œë¨")

        # st.info("ğŸ§  ì´ë¯¸ì§€ ì„ë² ë”© ì¤‘...")

        # vectors = [image_embedder.embed_image(img) for img, _ in all_images]
        # metadatas = [meta for _, meta in all_images]

        # st.success(f"âœ… ì„ë² ë”© ì™„ë£Œ (vector dim: {len(vectors[0])})")
        # st.code(f"ì²« ë²ˆì§¸ ë²¡í„° preview: {vectors[0][:10]} ...")

        # st.write("### ğŸ”¢ ì˜ˆì‹œ ë©”íƒ€ë°ì´í„°:")
        # st.json(metadatas[0])
        
        # upload_image_embeddings_to_es(vectors, metadatas)
        # st.success("âœ… ì´ë¯¸ì§€ ì„ë² ë”© ë° ì—…ë¡œë“œ ì™„ë£Œ!")

query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

if query:
    embedder = get_embedder(mode, embedding_model)
    
    # # ì§ˆì˜ ì„ë² ë”©
    # if hasattr(embedder, "embed_query"):
    #     query_vec = embedder.embed_query(query)
    # else:
    #     query_vec = embedder.embed_query(query)

    # image_embed ëª¨ë“œì¼ ë•ŒëŠ” text embedder ë”°ë¡œ ì²˜ë¦¬
    if retriever_method == "hybrid_embedding":
        text_embedder, image_embedder = get_hybrid_embedder()
        query_vec = { #text_embedder.embed_query(query)
            "text": text_embedder.embed_query(query),
            "image": image_embedder.embed_text(query), # CLIPTextEmbedder or SigLIPTextEmbedder
        }
    
    elif mode == "image_embed":
        if embedding_model == "clip":
            query_embedder = CLIPTextEmbedder()
        elif embedding_model == "siglip":
            from rag_pipeline.embedder import SiglipTextEmbedder
            query_embedder = SiglipTextEmbedder()
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„ë² ë”© ëª¨ë¸: {embedding_model}")
        query_vec = query_embedder.embed_text(query)
    
    else: # text or image_ocr
        embedder = get_embedder(mode, embedding_model)
        if hasattr(embedder, "embed_query"):
            query_vec = embedder.embed_query(query)
        else:
            query_vec = embedder.embed_text(query)

    # ê²€ìƒ‰
    from rag_pipeline.retriever import get_retriever
    retriever = get_retriever(mode, retriever_type=retriever_method)
    # hits = retriever(query_vec)

    if retriever_method == "hybrid_embedding":
        hits = retriever(query_vec) # query_vec is a dict with 'text' and 'image'
    elif retriever_method == "hybrid_es":
        hits = retriever(query, query_vec)
    else:
        hits = retriever(query_vec)

    # ë¬¸ì„œ ì •ë¦¬
    # docs = [
    #     {
    #         "content": hit["_source"]["content"],   
    #         "metadata": hit["_source"].get("metadata", {})
    #     }
    #     for hit in hits
    # ]
    # ë¬¸ì„œ ì •ë¦¬
    if mode == "image_embed":
        docs = [
            {
                # contentëŠ” ì—†ìŒ
                "metadata": hit["_source"].get("metadata", {})
            }
            for hit in hits
        ]
    else:
        docs = [
            {
                "content": hit["_source"]["content"],
                "metadata": hit["_source"].get("metadata", {})
            }
            for hit in hits
        ]

    # rerank
    from rag_pipeline.reranker import rerank_documents
    # docs = rerank_documents(
    #     query=query,
    #     docs=docs,
    #     method=rerank_method,
    #     query_vec=query_vec,
    #     embedder=embedder,
    # )
    
    # ì¤‘ë³µ ì œê±°
    seen_sources = set()
    unique_docs = []
    for doc in docs:
        src = doc["metadata"].get("source", "")  # PDF íŒŒì¼ëª…
        if src not in seen_sources:
            unique_docs.append(doc)
            seen_sources.add(src)
    
    # rerank_methodê°€ noneì´ ì•„ë‹ˆê³  contentê°€ ìˆì„ ë•Œë§Œ reranking ìˆ˜í–‰
    if rerank_method != "none" and "content" in unique_docs[0]:
        docs = rerank_documents(
            query=query,
            docs=unique_docs,
            method=rerank_method,
            query_vec=query_vec,
            embedder=embedder,
        )
    else:
        docs = unique_docs

    # if rerank_method == "cosine":
    #     docs = rerank_cosine(query_vec, docs, embedder)

    #     st.markdown("### ğŸ” ìœ ì‚¬ ì´ë¯¸ì§€ ë¬¸ì„œ:")
    #     for i, hit in enumerate(hits):
    #         meta = hit["_source"]["metadata"]
    #         st.markdown(f"**{i+1}. {meta.get('source')} (p{meta.get('page')})**")
    
    # else: # text or image_ocr
    #     embedder = HuggingFaceEmbeddings(model_name="snunlp/KR-SBERT-V40K-klueNLI-augSTS")
    #     query_vec = embedder.embed_query(query)
    #     index_name = "text_docs" if mode == "text" else "ocr_docs"
    #     hits = search_similar_text(query_vec, index_name=index_name)

    #     docs = [
    #         {
    #             "content": hit["_source"]["content"],
    #             "metadata": hit["_source"].get("metadata", {})
    #         }
    #         for hit in hits
    #     ]

    #     if rerank_method == "cosine":
    #         docs = rerank_cosine(query_vec, docs, embedder)
    #     elif rerank_method == "cross-encoder":
    #         docs = rerank_crossencoder(query, docs)
    
    # ì¶œë ¥
    st.markdown("### ğŸ” ê²°ê³¼:")
    for i, doc in enumerate(unique_docs[:3]):
        # st.markdown(f"**{i+1}. {doc['metadata'].get('source', 'unknown')}**")
        # st.write(doc["content"][:500])
        meta = doc["metadata"]
        st.markdown(f"**{i+1}. {meta.get('source', 'unknown')} (p{meta.get('page', '-')})**")
    
        # ğŸ”§ contentê°€ ìˆìœ¼ë©´ ë³´ì—¬ì£¼ê³ , ì—†ìœ¼ë©´ "ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì„œ"ë¡œ í‘œì‹œ
        if "content" in doc:
            st.write(doc["content"][:500])
        else:
            st.info("ğŸ“· ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì„œì…ë‹ˆë‹¤ (í…ìŠ¤íŠ¸ ì—†ìŒ)")

            # âœ… ì´ë¯¸ì§€ë„ í•¨ê»˜ ì¶œë ¥
            if "all_images" in st.session_state:
                for img, img_meta in st.session_state.all_images:
                    if (
                        img_meta.get("source") == meta.get("source")
                        and img_meta.get("page") == meta.get("page")
                    ):
                        st.image(img, caption=f"{meta.get('source')} - p{meta.get('page')}")
                        break  # ê°€ì¥ ì²˜ìŒ ë§¤ì¹­ëœ ì´ë¯¸ì§€ë§Œ ì¶œë ¥

    from langchain.schema.document import Document as LCDocument
    if mode != "image_embed":
        llm = OpenAI(temperature=0.7)
        answer = run_llm_qa(query, [LCDocument(page_content=doc["content"],
                    metadata=doc["metadata"]) for doc in unique_docs[:3]], llm)
        st.markdown("### ğŸ’¡ ë‹µë³€:")
        st.write(answer)
    else:
        st.info("ğŸ“· ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì„œëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ì–´ LLM ë‹µë³€ ìƒì„±ì„ ìƒëµí•©ë‹ˆë‹¤.")

# TODO: text/image_ocr â†’ embedding â†’ ê²€ìƒ‰ â†’ rerank â†’ run_llm_qa
